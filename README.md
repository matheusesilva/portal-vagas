# Agregador de Vagas de Emprego

Este projeto implementa uma arquitetura serverless para identificar e estruturar vagas de emprego publicadas em portais de vagas. O pipeline utiliza AWS Lambda, DynamoDB, SQS, API Groq e um portal web hospedado no Elastic Beanstalk. O objetivo √© automatizar a coleta di√°ria de posts, identificar poss√≠veis vagas com base em palavras-chave definidas pelo usu√°rio e disponibilizar informa√ß√µes estruturadas em um painel acess√≠vel.

## Live view

http://portal-jobs-env-1.eba-yestrddp.us-east-1.elasticbeanstalk.com/

**Usu√°rio e senha demo:**
- demo@demo.com
- Demo-1234

## Arquitetura Geral

1. **Scraper de LinkedIn (Lambda + Playwright em Docker/ECR)**  
   - Executado 1x por dia.  
   - Acessa o portal de vagas, coleta posts recentes e extrai conte√∫do bruto. 
   - Envia posts para uma fila SQS.  
   - Empacotado como container Docker hospedado no Amazon ECR.

2. **Lambda de Enriquecimento com IA (Groq API)**  
   - Consome mensagens da fila no SQS.  
   - Envia o conte√∫do para a API Groq, que extrai dados estruturados da vaga.  
   - Os dados s√£o enviados para outra lista SQS.

3. **Lambda de Persist√™ncia**  
   - Consome da lista com os dados extra√≠dos pela IA.  
   - Armazena os dados da vaga em uma tabela DynamoDB.

4. **Autentica√ß√£o e Prefer√™ncias do Usu√°rio (Cognito + DynamoDB)**  
   - Usu√°rios podem criar conta via AWS Cognito.  
   - Cada usu√°rio define suas palavras-chave preferidas.  
   - As prefer√™ncias s√£o salvas em uma tabela do DynamoDB.

5. **Portal Web (AWS Elastic Beanstalk)**  
   - Interface onde usu√°rios fazem login e acessam suas prefer√™ncias.  
   - Exibe tamb√©m as vagas extra√≠das do DynamoDB.  
   - J√° implementado:  
     - P√°gina de login (Cognito).  
     - P√°gina inicial com visualiza√ß√£o e edi√ß√£o de prefer√™ncias.  

---

## Status do Projeto

### ‚úîÔ∏è Conclu√≠do
- P√°gina de login integrada ao Cognito.  
- P√°gina inicial da aplica√ß√£o.  
- Persist√™ncia das prefer√™ncias do usu√°rio em DynamoDB.  
- Configura√ß√£o das tabelas principais.  

### üîÑ Em andamento
- Deploy das Lambdas com Playwright dentro de container Docker hospedado no ECR.  
- Pipeline de scraping + classifica√ß√£o + IA + persist√™ncia.

### üîú Pr√≥ximos Passos
- Criar Dockerfile do scraper.  
- Subir imagem para o ECR.  
- Criar Lambda baseada em container.  
- Integrar com SQS e IAM roles.  
- Implementar as demais Lambdas da pipeline.  
- Finalizar exibi√ß√£o das vagas no portal.

---

## Tecnologias Utilizadas

- **AWS Lambda (serverless compute)**
- **AWS SQS (filas de processamento)**
- **AWS DynamoDB (persist√™ncia NoSQL)**
- **AWS Cognito (autentica√ß√£o de usu√°rios)**
- **AWS Elastic Beanstalk (portal web)**
- **Amazon ECR + Docker + Playwright (scraper)**
- **Groq API (extra√ß√£o inteligente de dados)**
- **Node.js / JavaScript**
- **React (frontend)**

---

## Fluxo de Dados

```mermaid
flowchart TD

A[Scraper Lambda<br>Playwright + Docker] -->|posts suspeitos| B[SQS<br>queue_raw_posts]
B --> C[Lambda de Enriquecimento<br>Groq API]
C -->|vaga confirmada| D[SQS<br>queue_validated_jobs]
D --> E[Lambda de Persist√™ncia]
E --> F[DynamoDB<br>jobs_table]
G[Cognito] --> H[Portal Web<br>Elastic Beanstalk]
H --> I[DynamoDB<br>user_preferences_table]
F --> H
